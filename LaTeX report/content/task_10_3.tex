\documentclass[../main.tex]{subfiles}
\begin{document}
	
\section{Optimal Control of Pitch/Travel with Feedback (LQ)}
In this task we add feedback to the optimal controller that we developed in \cref{kap:Part2OptimalControlWithoutFeedback}

\subsection{Introducing feedback}
Feedback is introduced to \cref{eq:lab2_discrete_system} by using the following term for the input:
\begin{equation}\label{eq:lab3_feedback}
	u_k = u_k^* - \bm{K}^T(\bm x_k - \bm x_k^*)
\end{equation}, 
where $ u_k^* $ and $ \bm x_k^* $ is, respectively, the optimal input- and state-trajectory calculated with\todo{add cref to the equation doing this}, $ \bm x_k $ is the state and $ \bm K $ is the feedback gain matrix.
\todo[inline]{Do we need to say something about k: \\ 
$ x_k $ is the state at timestep k (or something like that)}.

In \cref{eq:lab3_feedback}, the last term $ -\bm{K}^T(\bm x_k - \bm x_k^*) $ is the correction term. If there is a deviation in the actual state $ \bm x_k $ and the optimal state $ \bm x_k^* $, this term will correct\todo{correct is not a good word here} the input $ u_k $ so the next state $ \bm x_{k + 1} $ comes closer to the optimal state. 
\todo[inline]{Dette er en svÃ¦rt kronglete setning. Formuler denne bedre}

The next challenge is to find a good feedback gain matrix $ \bm K $, that gives us a good behavior for the system. We will use a LQ controller for this task.

\subsection{LQ controller}
\textit{Briefly explain LQ controller. Especially, but not limited to, what is the role of the matrices Q and R? Justify your choice of weights.}

An LQ (or linear-quadratic) controller, solves the quadratic objective function given by: 
\begin{equation}
    J = \sum^\infty_{i=0} \Delta x_{i+1}^\top Q \Delta x_{i+1} + \Delta u_i^\top R \Delta u_i, \quad Q \ge0, \quad R > 0
\end{equation}


is an optimal feedback controller that can be applied to a linear model $\Delta x=A\Delta x_i + B \Delta u_i$ with a quadratic cost function:
Here $ \Delta x = x - x^*$ and $\Delta u = u - u^*$ are deviations from the optimal trajectory.

The matrix $Q$ and the scalar $R$ are weights in the optimalization problem. The value of $Q$ determines how much deviation in the state value should be penalized, while the value of $R$ determines how much input-usage should be punished. This allows the designer to optimize the regulator to the specific implementation: A system where the input is cheap (like the helicopter used in this assignment) would have a relatively small value of $R$ compared to $Q$.

\subsection{Model Predictive Control}
\textit{Answer 10.3.1.3 here.}

\subsection{Experimental results}
\textit{Printouts of data from relevant experiments (plots).
Discussion and analysis of the results.
Answer 10.3.2.5 here.}

\subsection{MATLAB and Simulink}
\textit{Code and diagrams go here}
\end{document}